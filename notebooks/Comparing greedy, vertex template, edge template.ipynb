{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1538f0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.GreedyPolicy"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using EdgeFlip\n",
    "include(\"../greedy_policy.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2add05c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nref = 1\n",
    "nflips = 8\n",
    "maxflips = ceil(Int,1.2nflips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb15240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GameEnv\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = EdgeFlip.GameEnv(nref,nflips,fixed_reset=false,maxflips=maxflips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb676c4f",
   "metadata": {},
   "source": [
    "## Deploy Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d791de84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075987856587855"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_trajectories = 5000\n",
    "gd_avg = GreedyPolicy.average_normalized_returns(env, num_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c5e2d",
   "metadata": {},
   "source": [
    "## Linear policy using vertex template score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c32a44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module PolicyGradient.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Main.PolicyGradient"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "using Distributions: Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42baf828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module PolicyGradient.\n"
     ]
    }
   ],
   "source": [
    "include(\"../global_policy_gradient.jl\")\n",
    "\n",
    "function PolicyGradient.state(env::EdgeFlip.GameEnv)\n",
    "    return EdgeFlip.vertex_template_score(env)\n",
    "end\n",
    "\n",
    "function PolicyGradient.step!(env::EdgeFlip.GameEnv, action)\n",
    "    EdgeFlip.step!(env, action)\n",
    "end\n",
    "\n",
    "function PolicyGradient.is_terminated(env::EdgeFlip.GameEnv)\n",
    "    return EdgeFlip.is_terminated(env)\n",
    "end\n",
    "\n",
    "function PolicyGradient.reward(env::EdgeFlip.GameEnv)\n",
    "    return EdgeFlip.reward(env)\n",
    "end\n",
    "\n",
    "function PolicyGradient.reset!(env::EdgeFlip.GameEnv)\n",
    "    EdgeFlip.reset!(env)\n",
    "end\n",
    "\n",
    "function PolicyGradient.score(env::EdgeFlip.GameEnv)\n",
    "    return EdgeFlip.score(env)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac906c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LinearPolicy\n",
    "    model::Any\n",
    "    function LinearPolicy()\n",
    "        model = Dense(4,1)\n",
    "        new(model)\n",
    "    end\n",
    "end\n",
    "\n",
    "function (p::LinearPolicy)(s)\n",
    "    return vec(p.model(s))\n",
    "end\n",
    "\n",
    "Flux.@functor LinearPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee28535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearPolicy(Dense(4, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = LinearPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b30d3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 1000\n",
    "num_trajectories = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e777e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 \t loss: 7.5835 \t avg return: 0.86\n",
      "epoch: 200 \t loss: 5.2152 \t avg return: 0.91\n",
      "epoch: 300 \t loss: 1.3215 \t avg return: 0.88\n",
      "epoch: 400 \t loss: 1.0646 \t avg return: 0.87\n",
      "epoch: 500 \t loss: 3.5899 \t avg return: 0.92\n",
      "epoch: 600 \t loss: 5.8473 \t avg return: 0.92\n",
      "epoch: 700 \t loss: 3.0621 \t avg return: 0.89\n",
      "epoch: 800 \t loss: 1.4156 \t avg return: 0.90\n",
      "epoch: 900 \t loss: 0.7322 \t avg return: 0.90\n",
      "epoch: 1000 \t loss: 4.2037 \t avg return: 0.91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], Any[0.8592665945165945, 0.9095813075813075, 0.8828950216450216, 0.8653055555555557, 0.9151074203574204, 0.9189873737373737, 0.8891199078699078, 0.900023088023088, 0.8966511544011544, 0.9088748196248195])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_history, return_history = PolicyGradient.run_training_loop(\n",
    "    env,\n",
    "    policy,\n",
    "    batch_size,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    num_trajectories,\n",
    "    estimate_every = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8cb4c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020641081141081"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_trajectories = 1000\n",
    "nn_avg = PolicyGradient.average_normalized_returns(env, policy, num_test_trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7629c",
   "metadata": {},
   "source": [
    "## Edge template policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfb91a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "function PolicyGradient.state(env::EdgeFlip.GameEnv)\n",
    "    vs = EdgeFlip.vertex_template_score(env)\n",
    "    et = EdgeFlip.edge_template(env)\n",
    "    return vs, et\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "275f2f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edge_state (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function edge_state(ep, et, boundary)\n",
    "   es = [e == 0 ? boundary : ep[e] for e in et] \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8b99c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct EdgePolicy\n",
    "    vertex\n",
    "    edge\n",
    "    boundary\n",
    "    function EdgePolicy()\n",
    "        vertex = Dense(4,1)\n",
    "        edge = Dense(5,1)\n",
    "        boundary = Flux.glorot_uniform(1)\n",
    "        new(vertex, edge, boundary)\n",
    "    end\n",
    "end\n",
    "\n",
    "function (p::EdgePolicy)(state)\n",
    "   vs, et = state[1], state[2]\n",
    "    ep = p.vertex(vs)\n",
    "    es = edge_state(ep, et, p.boundary[1])\n",
    "    \n",
    "    logits = vec(p.edge(es))\n",
    "    return logits\n",
    "end\n",
    "\n",
    "Flux.@functor EdgePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8a57fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgePolicy(Dense(4, 1), Dense(5, 1), Float32[-0.29828715])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = EdgePolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d14e892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100 \t loss: -5670.5347 \t avg return: -0.68\n",
      "epoch: 200 \t loss: -88216.7031 \t avg return: -1.22\n",
      "epoch: 300 \t loss: -232141.7500 \t avg return: -1.39\n",
      "epoch: 400 \t loss: -306357.1250 \t avg return: -1.38\n",
      "epoch: 500 \t loss: -322637.2188 \t avg return: -1.26\n",
      "epoch: 600 \t loss: -1693660.0000 \t avg return: -1.28\n",
      "epoch: 700 \t loss: -2429977.5000 \t avg return: -1.30\n",
      "epoch: 800 \t loss: -2292006.0000 \t avg return: -1.37\n",
      "epoch: 900 \t loss: -2157647.7500 \t avg return: -1.24\n",
      "epoch: 1000 \t loss: -1994961.3750 \t avg return: -1.39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], Any[-0.682316267066267, -1.2224545177045176, -1.3887792207792204, -1.3764303751803753, -1.2615093795093795, -1.2760677655677657, -1.3029892329892327, -1.3696277611277612, -1.240140193140193, -1.3936442723942724])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_history, return_history = PolicyGradient.run_training_loop(\n",
    "    env,\n",
    "    policy,\n",
    "    batch_size,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    num_trajectories,\n",
    "    estimate_every = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a232c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
